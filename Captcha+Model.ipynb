{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Model for identifying Captchas from the given dataset.\n",
    "1. After taking a close look at the labels in the dataset it is observed that they are all of same length. \n",
    "2. As the labels are of same lengths it is not required to use complex networks like LSTM . So I built a custom architecture with 2 convolutional blocks . This architecture is trained to spit out 5 categories. The network is trained using adam optimiser and used categorical_crossentropy as the loss function. \n",
    "3. The data was split into 30000 for training , 10000 for validation and 2971 for test data set.\n",
    "4. The model achieved validation accuracy of above 97% and test accuracy of 94.88 %\n",
    "5. Tried models like resnet with 4 blocks but it turned to be expensive for the given dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Activation,merge,AveragePooling2D,SeparableConv2D,Conv2D,MaxPooling2D,Dense,Lambda,Flatten,BatchNormalization,Input,Dropout\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels2.txt',names=['img','label'])\n",
    "files = glob('dataset50000/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_list = set()\n",
    "for x in labels.label:\n",
    "    char_list.update(list(x))\n",
    "char_list = list(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels['img'] = labels['img'].apply(lambda x : 'dataset50000/'+x)\n",
    "labels['outputarr'] = labels['label'].apply(lambda x:list(x))\n",
    "test_data = labels.iloc[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for f in labels.img:\n",
    "    ima = np.asarray(Image.open(f))\n",
    "    images.append(ima)\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = np.vstack(labels.outputarr.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_categorical_(targs):\n",
    "    index_list = []\n",
    "    targs = [targets[:,i:i+1] for i in range(5)]\n",
    "    for t in targs:\n",
    "        index = [char_list.index(v) for v in t]\n",
    "        categorical = to_categorical(index,37)\n",
    "        index_list.append(categorical)\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = to_categorical_(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = images[:30000]\n",
    "x_val = images[30000:40000]\n",
    "x_test = images[40000:]\n",
    "y_train = [y[:30000] for y in Y]\n",
    "y_val = [y[30000:40000] for y in Y]\n",
    "y_test = [y[40000:] for y in Y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(x,filters,n):\n",
    "    for _ in range(n):\n",
    "        x = Conv2D(filters,3,3,activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters,3,3,activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "    return x\n",
    "d = 0.4\n",
    "input = Input(shape = (80,215,3))\n",
    "x = Lambda(lambda x: x/255)(input)\n",
    "for f in [64,128]:\n",
    "    x = conv_block(x,f,2)    \n",
    "x = Flatten()(x)\n",
    "output = []\n",
    "x = Dense(500,activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(d)(x)\n",
    "x = Dense(250,activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(d)(x)\n",
    "for _ in range(5):\n",
    "    output.append(Dense(37,activation='softmax')(x))\n",
    "model = Model(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_weights = [0.2] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile('adam','categorical_crossentropy',loss_weights=loss_weights,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('captcha.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = model.optimizer.lr/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 123s - loss: 0.0803 - dense_17_loss: 0.0739 - dense_18_loss: 0.0836 - dense_19_loss: 0.0957 - dense_20_loss: 0.0794 - dense_21_loss: 0.0691 - dense_17_acc: 0.9757 - dense_18_acc: 0.9772 - dense_19_acc: 0.9724 - dense_20_acc: 0.9764 - dense_21_acc: 0.9806 - val_loss: 0.1123 - val_dense_17_loss: 0.1227 - val_dense_18_loss: 0.1044 - val_dense_19_loss: 0.1655 - val_dense_20_loss: 0.1204 - val_dense_21_loss: 0.0483 - val_dense_17_acc: 0.9572 - val_dense_18_acc: 0.9791 - val_dense_19_acc: 0.9653 - val_dense_20_acc: 0.9718 - val_dense_21_acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6466d3df28>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=128,nb_epoch=1 , validation_data=(x_val,y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights('captcha.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_index = [np.argmax(predictions[i],1) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_labels = np.dstack(predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for label in np.dstack(predicted_index)[0]:\n",
    "    l = [char_list[l] for l in label]\n",
    "    preds.append(''.join(l))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishnu/miniconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_data['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = np.sum(test_data['label'] == test_data['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = test_data.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.883877482329183"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * correct/total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
